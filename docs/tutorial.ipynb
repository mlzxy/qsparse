{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8e7c831-df2b-4202-aca3-c24ecbe14ce4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tutorial\n",
    "\n",
    "In this tutorial, we will give a brief introduction on the quantization and pruning techniques upon which QSPARSE is built. Using our library, we guide you through the building of a image classification neural network with channel pruning and both weights and activations quantized.\n",
    "\n",
    "\n",
    "> If you are already familiar with quantization and pruning methods and want to learn the programming syntax, please fast forward to [Building Network with QSPARSE](#building-network-with-qsparse)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac640b8b-db84-45b2-9f79-467797912e87",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "Quantization and pruning are core techniques used to reduce the inference costs of deep neural networks and have been studied extensively. \n",
    "\n",
    "<figure style=\"text-align:center;font-style:italic\"> \n",
    "  <img src=\"../docs/assets/framework.png\" />\n",
    "  <figcaption>Conceptual diagram of the computational graph of a network whose weights and activations are quantized and pruned using QSPARSE, where the \"prune\" and \"quantize\" blocks represent operators injected.</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "### Quantization\n",
    "\n",
    "Approaches to quantization are often divided into two categories: \n",
    "\n",
    "1. Post-training quantization\n",
    "2. Quantization aware training\n",
    "\n",
    "The former applies quantization after a network has been trained, and the latter quantizes the network during training and thereby reduces the quantization error throughout training process and usually yields superior performance. Here, we focus on quantization aware training by injecting `quantization operator` into the training computational graph. Our quantization operator implements a variant of STE-based uniform quantization algorithm introduced in our MDPI publication. \n",
    "\n",
    "\n",
    "### Pruning\n",
    "\n",
    "Magnitude-based pruning is often considered one of the best practice to produce sparse network during training. Through using activation or weight magnitude as a proxy of importance, neurons or channels with smaller magnitude are removed. In practice, the element removal is accomplished by resetting them to zero through multiplication with a binary mask. The elmement removal and magnitude estimation are done by the `pruning operator` injected in the computational graph. Our pruning operator supports unstructured and structured pruning, and can be targeted to support layerwise pruning, as proposed in our MDPI publication, and stepwise pruning as proposed by [Zhu et al.](https://arxiv.org/pdf/1710.01878.pdf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4831cae7-2e46-4ba3-a036-94d92070005c",
   "metadata": {},
   "source": [
    "## Building Network with QSPARSE\n",
    "\n",
    "With the above methods in mind, in the following, we will use QSPARSE to build a quantized and sparse network upon the below full precision network borrowed from pytorch official [MNIST example](https://github.com/pytorch/examples/blob/master/mnist/main.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aaa0ed2-6a0d-4dd9-bda0-892550889bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83951b94-d85b-49a5-a6ae-89582e729c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv_part): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (linear_part): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_part = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "        )\n",
    "        self.linear_part = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(9216, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_part(x)\n",
    "        x = self.linear_part(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06365f8-5c6d-4778-9aa4-1f5d210dd89f",
   "metadata": {},
   "source": [
    "Next, we start by building a pruned and quantized convolution layer with relu activation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c40ce57-bd9e-4610-9d37-7a3100bde89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsparse import prune, quantize, set_qsparse_options\n",
    "set_qsparse_options(log_on_created=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd4dce7a-719b-461e-a7b8-eb3e60fe9fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(\n",
       "    1, 32, kernel_size=(3, 3), stride=(1, 1)\n",
       "    (quantize): QuantizeLayer(bits=4, timeout=100, callback=ScalerQuantizer)\n",
       "  )\n",
       "  (1): ReLU()\n",
       "  (2): PruneLayer(sparsity=0.5, start=200, interval=10, repetition=4, dimensions={1})\n",
       "  (3): QuantizeLayer(bits=4, timeout=100, callback=ScalerQuantizer)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Sequential(\n",
    "    quantize(nn.Conv2d(1, 32, 3), bits=4, timeout=100, channelwise=-1, name=\"weight quantization\"),\n",
    "    nn.ReLU(),\n",
    "    prune(sparsity=0.5, start=200, interval=10, repetition=4, dimensions={1}, name=\"channel pruning with activation magnitude\"), \n",
    "    quantize(bits=4, timeout=100, channelwise=1, name=\"activation quantization\"),\n",
    ")\n",
    "\n",
    "conv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20e35b6-a7cc-4525-a47a-92d6799ac1d3",
   "metadata": {},
   "source": [
    "- `timeout` denotes the steps when the quantization operator activates.\n",
    "- `start, interval, repetition` denote the sparsification schedule, as $t_0, \\Delta t, n$ in [Zhu et al.](https://arxiv.org/pdf/1710.01878.pdf).\n",
    "- `dimensions={1}` denotes channel pruning.\n",
    "\n",
    "These operators will activate at the corresponding steps, like following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96974eba-ad79-4203-abdc-aac781516e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mquantizing weight quantization with 4 bits\u001b[0m\n",
      "\u001b[33mquantizing activation quantization with 4 bits\u001b[0m\n",
      "\u001b[33m[Prune @ channel pruning with activation magnitude] [Step 200] pruned 0.29\u001b[0m\n",
      "\u001b[33mStart pruning at channel pruning with activation magnitude @ 200\u001b[0m\n",
      "\u001b[33m[Prune @ channel pruning with activation magnitude] [Step 210] pruned 0.44\u001b[0m\n",
      "\u001b[33m[Prune @ channel pruning with activation magnitude] [Step 220] pruned 0.49\u001b[0m\n",
      "\u001b[33m[Prune @ channel pruning with activation magnitude] [Step 230] pruned 0.50\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data = torch.rand((1, 1, 32, 32))\n",
    "for _ in range(241):\n",
    "    conv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eaaf5f58-1cea-4ad6-9c3f-8ff942e2cc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sparsity', 0.5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"sparsity\", 1 - conv[2].mask.sum().item() / conv[2].mask.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fb2782f-2252-472d-ba8a-f569287a7243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.0411]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv[0].quantize.weight # represent the `1/s` in equation (2) in the MDPI publication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c029b41-97f5-4766-ab8d-ef0e7961df11",
   "metadata": {},
   "source": [
    "However, it requires lots of repetitive work to rewrite a network definition with `prune` and `quantize` injected. Therefore, we provide a `convert` function to automaticaly inject them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7b4f15c-b9a7-4f48-9813-1f91219fcd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsparse import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "551a4533-9e7a-45db-8cab-9fb73105bfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply `prunesparsity=0.75, start=1000, interval=1000, repetition=4, dimensions={1}` on the .conv_part.2 activation\n",
      "Apply `prunesparsity=0.75, start=1000, interval=1000, repetition=4, dimensions={1}` on the .conv_part.5 activation\n",
      "Exclude .linear_part.3 activation\n",
      "Apply `quantizebits=4, timeout=500, callback=scalerquantizer` on the .conv_part.0 weight\n",
      "Apply `quantizebits=4, timeout=500, callback=scalerquantizer` on the .conv_part.3 weight\n",
      "Apply `quantizebits=4, timeout=500, callback=scalerquantizer` on the .linear_part.1 weight\n",
      "Apply `quantizebits=4, timeout=500, callback=scalerquantizer` on the .linear_part.5 weight\n",
      "Apply `quantizebits=4, timeout=500, callback=scalerquantizer` on the .conv_part.2 activation\n",
      "Apply `quantizebits=4, timeout=500, callback=scalerquantizer` on the .conv_part.5 activation\n",
      "Apply `quantizebits=4, timeout=500, callback=scalerquantizer` on the .linear_part.3 activation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): QuantizeLayer(bits=4, timeout=500, callback=ScalerQuantizer)\n",
       "  (1): Net(\n",
       "    (conv_part): Sequential(\n",
       "      (0): Conv2d(\n",
       "        1, 32, kernel_size=(3, 3), stride=(1, 1)\n",
       "        (quantize): QuantizeLayer(bits=4, timeout=500, callback=ScalerQuantizer)\n",
       "      )\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): PruneLayer(sparsity=0.75, start=1000, interval=1000, repetition=4, dimensions={1})\n",
       "        )\n",
       "        (1): QuantizeLayer(bits=4, timeout=500, callback=ScalerQuantizer)\n",
       "      )\n",
       "      (3): Conv2d(\n",
       "        32, 64, kernel_size=(3, 3), stride=(1, 1)\n",
       "        (quantize): QuantizeLayer(bits=4, timeout=500, callback=ScalerQuantizer)\n",
       "      )\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): PruneLayer(sparsity=0.75, start=1000, interval=1000, repetition=4, dimensions={1})\n",
       "        )\n",
       "        (1): QuantizeLayer(bits=4, timeout=500, callback=ScalerQuantizer)\n",
       "      )\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (linear_part): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Linear(\n",
       "        in_features=9216, out_features=128, bias=True\n",
       "        (quantize): QuantizeLayer(bits=4, timeout=500, callback=ScalerQuantizer)\n",
       "      )\n",
       "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): QuantizeLayer(bits=4, timeout=500, callback=ScalerQuantizer)\n",
       "      )\n",
       "      (4): Dropout(p=0.5, inplace=False)\n",
       "      (5): Linear(\n",
       "        in_features=128, out_features=10, bias=True\n",
       "        (quantize): QuantizeLayer(bits=4, timeout=500, callback=ScalerQuantizer)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCH_SIZE = 100\n",
    "\n",
    "net = convert(net, prune(sparsity=0.75, dimensions={1}),  # structure pruning\n",
    "                         activation_layers=[nn.ReLU],     # inject after the ReLU module\n",
    "                         excluded_activation_layer_indexes=[(nn.ReLU, [-1])]) # exclude the last relu layer \n",
    "\n",
    "net = convert(net, quantize(bits=4, channelwise=-1, timeout=5*EPOCH_SIZE), # tensorwise quantization                        \n",
    "                   activation_layers=[nn.ReLU], # activation quantization, inject after the ReLU module\n",
    "                   weight_layers=[nn.Conv2d, nn.Linear], # weight quantization, inject on Conv2d and Linear modules\n",
    "                   input=True) # also quantize input\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0a23c9-d3ad-4ae9-9dea-9da80d4e3bd2",
   "metadata": {},
   "source": [
    "We can further apply layerwise pruning instead of designing stepwise sparsification schedule by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3fa7b52-c976-4aed-8556-a637201f31f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPruning stops at iteration - 282.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from qsparse.sparse import devise_layerwise_pruning_schedule\n",
    "final_net = devise_layerwise_pruning_schedule(net, start=2 * EPOCH_SIZE, interval=0.4 * EPOCH_SIZE, mask_refresh_interval=0.1 * EPOCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678d53c0-4e98-4347-91c1-0128f02c0756",
   "metadata": {},
   "source": [
    "The diff between the stepwise pruning and layerwise pruning network configurations:\n",
    "\n",
    "\n",
    "```diff\n",
    "--- old.py\t2022-08-03 13:35:43.000000000 +0800\n",
    "+++ new.py\t2022-08-03 13:35:42.000000000 +0800\n",
    "@@ -10,7 +10,7 @@\n",
    "       (2): Sequential(\n",
    "         (0): Sequential(\n",
    "           (0): ReLU()\n",
    "-          (1): PruneLayer(sparsity=0.75, start=1000, interval=1000, repetition=4, dimensions={1})\n",
    "+          (1): PruneLayer(sparsity=0.75, start=200, interval=1000, repetition=1, dimensions={1})\n",
    "         )\n",
    "         (1): QuantizeLayer(bits=4, timeout=500, callback=ScalerQuantizer)\n",
    "       )\n",
    "@@ -22,7 +22,7 @@\n",
    "       (5): Sequential(\n",
    "         (0): Sequential(\n",
    "           (0): ReLU()\n",
    "-          (1): PruneLayer(sparsity=0.75, start=1000, interval=1000, repetition=4, dimensions={1})\n",
    "+          (1): PruneLayer(sparsity=0.75, start=241.0, interval=1000, repetition=1, dimensions={1})\n",
    "         )\n",
    "         (1): QuantizeLayer(bits=4, timeout=500, callback=ScalerQuantizer)\n",
    "       )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93285085-2dd4-4ff3-bda2-2fc840106d80",
   "metadata": {},
   "source": [
    "The full example of training MNIST classifier with different pruning and quantization configurations can be found at [examples/mnist.py](https://github.com/mlzxy/qsparse/blob/main/examples/). More examples can be found in [mdpi2022](https://github.com/mlzxy/mdpi2022).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2cc56-7486-4eb0-8eb2-579955f13321",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we introduce some basics about joint quantization and pruning training, and the implementation of this training paradigm with QSPARSE. Next, we introduce more [advanced usage](../advanced_usage/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
